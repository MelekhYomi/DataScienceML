{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e3fe435-4023-415b-a737-53d2250b8060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c943fe7-ab65-4dfe-816d-958265837e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame:\n",
      "    ID     Name   Age Department   Salary           City\n",
      "0  101    Alice  25.0         HR  50000.0       New York\n",
      "1  102      Bob  30.0         IT  60000.0    Los Angeles\n",
      "2  103  Charlie  35.0    Finance  70000.0        Chicago\n",
      "3  104    David  40.0  Marketing  80000.0  San Francisco\n",
      "4  105      Eve   NaN         IT  75000.0        Houston\n"
     ]
    }
   ],
   "source": [
    "# 1. Read the CSV file using pandas.\n",
    "file_path = 'C:/Users/Admin/Downloads/sample_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Initial DataFrame:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb837b64-967a-46e7-80c0-7aa5a27fdde9",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce66a4f-176f-47ae-93e5-c128d4f0d318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "ID            0\n",
      "Name          0\n",
      "Age           1\n",
      "Department    0\n",
      "Salary        1\n",
      "City          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column.\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb182cd4-0fc5-4aad-a9c9-8f404da6800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after dropping missing values:\n",
      "    ID     Name   Age Department   Salary           City\n",
      "0  101    Alice  25.0         HR  50000.0       New York\n",
      "1  102      Bob  30.0         IT  60000.0    Los Angeles\n",
      "2  103  Charlie  35.0    Finance  70000.0        Chicago\n",
      "3  104    David  40.0  Marketing  80000.0  San Francisco\n",
      "5  106    Frank  45.0    Finance  65000.0        Seattle\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with any missing values.\n",
    "df_cleaned = df.dropna()\n",
    "print(\"\\nDataFrame after dropping missing values:\")\n",
    "print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7b0e312-37c9-4ed2-8fb2-fbd73e797a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types after conversion:\n",
      "ID              int64\n",
      "Name           object\n",
      "Age           float64\n",
      "Department     object\n",
      "Salary        float64\n",
      "City           object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_16852\\1670180509.py:4: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='ignore')\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_16852\\1670180509.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# Ensure data is in appropriate data types.\n",
    "# (Attempt to convert each column to numeric if possible, ignoring errors)\n",
    "for col in df_cleaned.columns:\n",
    "    df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='ignore')\n",
    "\n",
    "print(\"\\nData types after conversion:\")\n",
    "print(df_cleaned.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd35c46c-47c0-4f70-8137-c71f60f0cbb3",
   "metadata": {},
   "source": [
    "# 3. Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6942b643-805b-43d9-b269-bb1285ecaee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numeric columns available for filtering/sorting: ['ID', 'Age', 'Salary']\n",
      "\n",
      "Filtered DataFrame (rows where 'ID' > 105.0):\n",
      "    ID   Name   Age Department   Salary     City\n",
      "5  106  Frank  45.0    Finance  65000.0  Seattle\n",
      "6  107  Grace  50.0         HR  72000.0   Boston\n",
      "7  108   Hank  28.0  Marketing  55000.0   Denver\n",
      "8  109    Ivy  33.0         IT  62000.0    Miami\n",
      "\n",
      "Sorted DataFrame by 'ID' in descending order:\n",
      "    ID   Name   Age Department   Salary     City\n",
      "8  109    Ivy  33.0         IT  62000.0    Miami\n",
      "7  108   Hank  28.0  Marketing  55000.0   Denver\n",
      "6  107  Grace  50.0         HR  72000.0   Boston\n",
      "5  106  Frank  45.0    Finance  65000.0  Seattle\n"
     ]
    }
   ],
   "source": [
    "# For demonstration, we will filter and sort using the first numeric column found.\n",
    "numeric_cols = df_cleaned.select_dtypes(include=['number']).columns.tolist()\n",
    "print(\"\\nNumeric columns available for filtering/sorting:\", numeric_cols)\n",
    "\n",
    "if numeric_cols:\n",
    "    # Select the first numeric column for our operations.\n",
    "    filter_col = numeric_cols[0]\n",
    "    \n",
    "    # Example filtering: keep rows where the chosen numeric column's value is greater than its median.\n",
    "    median_val = df_cleaned[filter_col].median()\n",
    "    filtered_df = df_cleaned[df_cleaned[filter_col] > median_val]\n",
    "    print(f\"\\nFiltered DataFrame (rows where '{filter_col}' > {median_val}):\")\n",
    "    print(filtered_df.head())\n",
    "    \n",
    "    # Sorting: sort the filtered data in descending order based on the same column.\n",
    "    sorted_df = filtered_df.sort_values(by=filter_col, ascending=False)\n",
    "    print(f\"\\nSorted DataFrame by '{filter_col}' in descending order:\")\n",
    "    print(sorted_df.head())\n",
    "else:\n",
    "    print(\"\\nNo numeric columns available for filtering or sorting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6aa77e-9196-4612-b6eb-f83cf3a9f57c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
